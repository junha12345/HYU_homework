{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice 5: Data Manipulation with Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Transforming Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "# Python pickle module is used for serializing and de-serializing a Python object structure. \n",
    "# Any object in Python can be pickled so that it can be saved on disk. \n",
    "# What pickle does is that it “serializes” the object first before writing it to file. \n",
    "# Pickling is a way to convert a python object (list, dict, etc.) into a character stream. \n",
    "# The idea is that this character stream contains all the information necessary to reconstruct the object in another python script.\n",
    "# https://www.geeksforgeeks.org/understanding-python-pickling-example/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('homeless_data.pkl', 'rb') as f:\n",
    "    homelessness = pickle.load(f)\n",
    "with open('walmart_sales.pkl', 'rb') as f:\n",
    "    sales = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspecting a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>state</th>\n",
       "      <th>individuals</th>\n",
       "      <th>family_members</th>\n",
       "      <th>state_pop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>East South Central</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>2570.0</td>\n",
       "      <td>864.0</td>\n",
       "      <td>4887681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pacific</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>1434.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>735139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mountain</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>7259.0</td>\n",
       "      <td>2606.0</td>\n",
       "      <td>7158024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>West South Central</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>2280.0</td>\n",
       "      <td>432.0</td>\n",
       "      <td>3009733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pacific</td>\n",
       "      <td>California</td>\n",
       "      <td>109008.0</td>\n",
       "      <td>20964.0</td>\n",
       "      <td>39461588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               region       state  individuals  family_members  state_pop\n",
       "0  East South Central     Alabama       2570.0           864.0    4887681\n",
       "1             Pacific      Alaska       1434.0           582.0     735139\n",
       "2            Mountain     Arizona       7259.0          2606.0    7158024\n",
       "3  West South Central    Arkansas       2280.0           432.0    3009733\n",
       "4             Pacific  California     109008.0         20964.0   39461588"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################################## TODO ##################################\n",
    "# Print the head of the homelessness data\n",
    "homelessness.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 51 entries, 0 to 50\n",
      "Data columns (total 5 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   region          51 non-null     object \n",
      " 1   state           51 non-null     object \n",
      " 2   individuals     51 non-null     float64\n",
      " 3   family_members  51 non-null     float64\n",
      " 4   state_pop       51 non-null     int64  \n",
      "dtypes: float64(2), int64(1), object(2)\n",
      "memory usage: 2.4+ KB\n"
     ]
    }
   ],
   "source": [
    "################################## TODO ##################################\n",
    "# Print information about homelessness\n",
    "homelessness.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51, 5)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################################## TODO ##################################\n",
    "# Print the shape of homelessness\n",
    "homelessness.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>individuals</th>\n",
       "      <th>family_members</th>\n",
       "      <th>state_pop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>51.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>5.100000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7225.784314</td>\n",
       "      <td>3504.882353</td>\n",
       "      <td>6.405637e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>15991.025083</td>\n",
       "      <td>7805.411811</td>\n",
       "      <td>7.327258e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>434.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>5.776010e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1446.500000</td>\n",
       "      <td>592.000000</td>\n",
       "      <td>1.777414e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3082.000000</td>\n",
       "      <td>1482.000000</td>\n",
       "      <td>4.461153e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6781.500000</td>\n",
       "      <td>3196.000000</td>\n",
       "      <td>7.340946e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>109008.000000</td>\n",
       "      <td>52070.000000</td>\n",
       "      <td>3.946159e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         individuals  family_members     state_pop\n",
       "count      51.000000       51.000000  5.100000e+01\n",
       "mean     7225.784314     3504.882353  6.405637e+06\n",
       "std     15991.025083     7805.411811  7.327258e+06\n",
       "min       434.000000       75.000000  5.776010e+05\n",
       "25%      1446.500000      592.000000  1.777414e+06\n",
       "50%      3082.000000     1482.000000  4.461153e+06\n",
       "75%      6781.500000     3196.000000  7.340946e+06\n",
       "max    109008.000000    52070.000000  3.946159e+07"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################################## TODO ##################################\n",
    "# Print a description of homelessness\n",
    "homelessness.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['East South Central' 'Alabama' 2570.0 864.0 4887681]\n",
      " ['Pacific' 'Alaska' 1434.0 582.0 735139]\n",
      " ['Mountain' 'Arizona' 7259.0 2606.0 7158024]\n",
      " ['West South Central' 'Arkansas' 2280.0 432.0 3009733]\n",
      " ['Pacific' 'California' 109008.0 20964.0 39461588]\n",
      " ['Mountain' 'Colorado' 7607.0 3250.0 5691287]\n",
      " ['New England' 'Connecticut' 2280.0 1696.0 3571520]\n",
      " ['South Atlantic' 'Delaware' 708.0 374.0 965479]\n",
      " ['South Atlantic' 'District of Columbia' 3770.0 3134.0 701547]\n",
      " ['South Atlantic' 'Florida' 21443.0 9587.0 21244317]\n",
      " ['South Atlantic' 'Georgia' 6943.0 2556.0 10511131]\n",
      " ['Pacific' 'Hawaii' 4131.0 2399.0 1420593]\n",
      " ['Mountain' 'Idaho' 1297.0 715.0 1750536]\n",
      " ['East North Central' 'Illinois' 6752.0 3891.0 12723071]\n",
      " ['East North Central' 'Indiana' 3776.0 1482.0 6695497]\n",
      " ['West North Central' 'Iowa' 1711.0 1038.0 3148618]\n",
      " ['West North Central' 'Kansas' 1443.0 773.0 2911359]\n",
      " ['East South Central' 'Kentucky' 2735.0 953.0 4461153]\n",
      " ['West South Central' 'Louisiana' 2540.0 519.0 4659690]\n",
      " ['New England' 'Maine' 1450.0 1066.0 1339057]\n",
      " ['South Atlantic' 'Maryland' 4914.0 2230.0 6035802]\n",
      " ['New England' 'Massachusetts' 6811.0 13257.0 6882635]\n",
      " ['East North Central' 'Michigan' 5209.0 3142.0 9984072]\n",
      " ['West North Central' 'Minnesota' 3993.0 3250.0 5606249]\n",
      " ['East South Central' 'Mississippi' 1024.0 328.0 2981020]\n",
      " ['West North Central' 'Missouri' 3776.0 2107.0 6121623]\n",
      " ['Mountain' 'Montana' 983.0 422.0 1060665]\n",
      " ['West North Central' 'Nebraska' 1745.0 676.0 1925614]\n",
      " ['Mountain' 'Nevada' 7058.0 486.0 3027341]\n",
      " ['New England' 'New Hampshire' 835.0 615.0 1353465]\n",
      " ['Mid-Atlantic' 'New Jersey' 6048.0 3350.0 8886025]\n",
      " ['Mountain' 'New Mexico' 1949.0 602.0 2092741]\n",
      " ['Mid-Atlantic' 'New York' 39827.0 52070.0 19530351]\n",
      " ['South Atlantic' 'North Carolina' 6451.0 2817.0 10381615]\n",
      " ['West North Central' 'North Dakota' 467.0 75.0 758080]\n",
      " ['East North Central' 'Ohio' 6929.0 3320.0 11676341]\n",
      " ['West South Central' 'Oklahoma' 2823.0 1048.0 3940235]\n",
      " ['Pacific' 'Oregon' 11139.0 3337.0 4181886]\n",
      " ['Mid-Atlantic' 'Pennsylvania' 8163.0 5349.0 12800922]\n",
      " ['New England' 'Rhode Island' 747.0 354.0 1058287]\n",
      " ['South Atlantic' 'South Carolina' 3082.0 851.0 5084156]\n",
      " ['West North Central' 'South Dakota' 836.0 323.0 878698]\n",
      " ['East South Central' 'Tennessee' 6139.0 1744.0 6771631]\n",
      " ['West South Central' 'Texas' 19199.0 6111.0 28628666]\n",
      " ['Mountain' 'Utah' 1904.0 972.0 3153550]\n",
      " ['New England' 'Vermont' 780.0 511.0 624358]\n",
      " ['South Atlantic' 'Virginia' 3928.0 2047.0 8501286]\n",
      " ['Pacific' 'Washington' 16424.0 5880.0 7523869]\n",
      " ['South Atlantic' 'West Virginia' 1021.0 222.0 1804291]\n",
      " ['East North Central' 'Wisconsin' 2740.0 2167.0 5807406]\n",
      " ['Mountain' 'Wyoming' 434.0 205.0 577601]]\n"
     ]
    }
   ],
   "source": [
    "# Print the values of homelessness\n",
    "print(homelessness.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['region', 'state', 'individuals', 'family_members', 'state_pop'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Print the column index of homelessness\n",
    "print(homelessness.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "            17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "            34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49,\n",
       "            50],\n",
       "           dtype='int64')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################################## TODO ##################################\n",
    "# Print the row index of homelessness\n",
    "homelessness.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting rows\n",
    "################################## TODO ##################################\n",
    "# Sort homelessness by individual\n",
    "homelessness_ind = homelessness.sort_values(\"individuals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                region         state  individuals  family_members  state_pop\n",
      "50            Mountain       Wyoming        434.0           205.0     577601\n",
      "34  West North Central  North Dakota        467.0            75.0     758080\n",
      "7       South Atlantic      Delaware        708.0           374.0     965479\n",
      "39         New England  Rhode Island        747.0           354.0    1058287\n",
      "45         New England       Vermont        780.0           511.0     624358\n"
     ]
    }
   ],
   "source": [
    "# Print the top few rows\n",
    "print(homelessness_ind.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################## TODO ################################## \n",
    "# Sort homelessness in the descending order of the number of family members\n",
    "homelessness_fam = homelessness.sort_values(\"family_members\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                region          state  individuals  family_members  state_pop\n",
      "34  West North Central   North Dakota        467.0            75.0     758080\n",
      "50            Mountain        Wyoming        434.0           205.0     577601\n",
      "48      South Atlantic  West Virginia       1021.0           222.0    1804291\n",
      "41  West North Central   South Dakota        836.0           323.0     878698\n",
      "24  East South Central    Mississippi       1024.0           328.0    2981020\n"
     ]
    }
   ],
   "source": [
    "# Print the top few rows\n",
    "print(homelessness_fam.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################## TODO ##################################\n",
    "# Sort homelessness by region, then descending family members\n",
    "homelessness_reg_fam = homelessness.sort_values([\"region\", \"family_members\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                region      state  individuals  family_members  state_pop\n",
      "14  East North Central    Indiana       3776.0          1482.0    6695497\n",
      "49  East North Central  Wisconsin       2740.0          2167.0    5807406\n",
      "22  East North Central   Michigan       5209.0          3142.0    9984072\n",
      "35  East North Central       Ohio       6929.0          3320.0   11676341\n",
      "13  East North Central   Illinois       6752.0          3891.0   12723071\n"
     ]
    }
   ],
   "source": [
    "# Print the top few rows\n",
    "print(homelessness_reg_fam.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>state</th>\n",
       "      <th>individuals</th>\n",
       "      <th>family_members</th>\n",
       "      <th>state_pop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>East North Central</td>\n",
       "      <td>Indiana</td>\n",
       "      <td>3776.0</td>\n",
       "      <td>1482.0</td>\n",
       "      <td>6695497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>East North Central</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>2740.0</td>\n",
       "      <td>2167.0</td>\n",
       "      <td>5807406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>East North Central</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>5209.0</td>\n",
       "      <td>3142.0</td>\n",
       "      <td>9984072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>East North Central</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>6929.0</td>\n",
       "      <td>3320.0</td>\n",
       "      <td>11676341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>East North Central</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>6752.0</td>\n",
       "      <td>3891.0</td>\n",
       "      <td>12723071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>East South Central</td>\n",
       "      <td>Mississippi</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>328.0</td>\n",
       "      <td>2981020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>East South Central</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>2570.0</td>\n",
       "      <td>864.0</td>\n",
       "      <td>4887681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>East South Central</td>\n",
       "      <td>Kentucky</td>\n",
       "      <td>2735.0</td>\n",
       "      <td>953.0</td>\n",
       "      <td>4461153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>East South Central</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>6139.0</td>\n",
       "      <td>1744.0</td>\n",
       "      <td>6771631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Mid-Atlantic</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>6048.0</td>\n",
       "      <td>3350.0</td>\n",
       "      <td>8886025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Mid-Atlantic</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>8163.0</td>\n",
       "      <td>5349.0</td>\n",
       "      <td>12800922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Mid-Atlantic</td>\n",
       "      <td>New York</td>\n",
       "      <td>39827.0</td>\n",
       "      <td>52070.0</td>\n",
       "      <td>19530351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Mountain</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>434.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>577601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Mountain</td>\n",
       "      <td>Montana</td>\n",
       "      <td>983.0</td>\n",
       "      <td>422.0</td>\n",
       "      <td>1060665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Mountain</td>\n",
       "      <td>Nevada</td>\n",
       "      <td>7058.0</td>\n",
       "      <td>486.0</td>\n",
       "      <td>3027341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Mountain</td>\n",
       "      <td>New Mexico</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>602.0</td>\n",
       "      <td>2092741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Mountain</td>\n",
       "      <td>Idaho</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>715.0</td>\n",
       "      <td>1750536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Mountain</td>\n",
       "      <td>Utah</td>\n",
       "      <td>1904.0</td>\n",
       "      <td>972.0</td>\n",
       "      <td>3153550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mountain</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>7259.0</td>\n",
       "      <td>2606.0</td>\n",
       "      <td>7158024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mountain</td>\n",
       "      <td>Colorado</td>\n",
       "      <td>7607.0</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>5691287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>New England</td>\n",
       "      <td>Rhode Island</td>\n",
       "      <td>747.0</td>\n",
       "      <td>354.0</td>\n",
       "      <td>1058287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>New England</td>\n",
       "      <td>Vermont</td>\n",
       "      <td>780.0</td>\n",
       "      <td>511.0</td>\n",
       "      <td>624358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>New England</td>\n",
       "      <td>New Hampshire</td>\n",
       "      <td>835.0</td>\n",
       "      <td>615.0</td>\n",
       "      <td>1353465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>New England</td>\n",
       "      <td>Maine</td>\n",
       "      <td>1450.0</td>\n",
       "      <td>1066.0</td>\n",
       "      <td>1339057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>New England</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>2280.0</td>\n",
       "      <td>1696.0</td>\n",
       "      <td>3571520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>New England</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>6811.0</td>\n",
       "      <td>13257.0</td>\n",
       "      <td>6882635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pacific</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>1434.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>735139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Pacific</td>\n",
       "      <td>Hawaii</td>\n",
       "      <td>4131.0</td>\n",
       "      <td>2399.0</td>\n",
       "      <td>1420593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Pacific</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>11139.0</td>\n",
       "      <td>3337.0</td>\n",
       "      <td>4181886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Pacific</td>\n",
       "      <td>Washington</td>\n",
       "      <td>16424.0</td>\n",
       "      <td>5880.0</td>\n",
       "      <td>7523869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pacific</td>\n",
       "      <td>California</td>\n",
       "      <td>109008.0</td>\n",
       "      <td>20964.0</td>\n",
       "      <td>39461588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>South Atlantic</td>\n",
       "      <td>West Virginia</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>1804291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>South Atlantic</td>\n",
       "      <td>Delaware</td>\n",
       "      <td>708.0</td>\n",
       "      <td>374.0</td>\n",
       "      <td>965479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>South Atlantic</td>\n",
       "      <td>South Carolina</td>\n",
       "      <td>3082.0</td>\n",
       "      <td>851.0</td>\n",
       "      <td>5084156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>South Atlantic</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>3928.0</td>\n",
       "      <td>2047.0</td>\n",
       "      <td>8501286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>South Atlantic</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>4914.0</td>\n",
       "      <td>2230.0</td>\n",
       "      <td>6035802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>South Atlantic</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>6943.0</td>\n",
       "      <td>2556.0</td>\n",
       "      <td>10511131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>South Atlantic</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>6451.0</td>\n",
       "      <td>2817.0</td>\n",
       "      <td>10381615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>South Atlantic</td>\n",
       "      <td>District of Columbia</td>\n",
       "      <td>3770.0</td>\n",
       "      <td>3134.0</td>\n",
       "      <td>701547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>South Atlantic</td>\n",
       "      <td>Florida</td>\n",
       "      <td>21443.0</td>\n",
       "      <td>9587.0</td>\n",
       "      <td>21244317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>West North Central</td>\n",
       "      <td>North Dakota</td>\n",
       "      <td>467.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>758080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>West North Central</td>\n",
       "      <td>South Dakota</td>\n",
       "      <td>836.0</td>\n",
       "      <td>323.0</td>\n",
       "      <td>878698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>West North Central</td>\n",
       "      <td>Nebraska</td>\n",
       "      <td>1745.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>1925614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>West North Central</td>\n",
       "      <td>Kansas</td>\n",
       "      <td>1443.0</td>\n",
       "      <td>773.0</td>\n",
       "      <td>2911359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>West North Central</td>\n",
       "      <td>Iowa</td>\n",
       "      <td>1711.0</td>\n",
       "      <td>1038.0</td>\n",
       "      <td>3148618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>West North Central</td>\n",
       "      <td>Missouri</td>\n",
       "      <td>3776.0</td>\n",
       "      <td>2107.0</td>\n",
       "      <td>6121623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>West North Central</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>3993.0</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>5606249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>West South Central</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>2280.0</td>\n",
       "      <td>432.0</td>\n",
       "      <td>3009733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>West South Central</td>\n",
       "      <td>Louisiana</td>\n",
       "      <td>2540.0</td>\n",
       "      <td>519.0</td>\n",
       "      <td>4659690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>West South Central</td>\n",
       "      <td>Oklahoma</td>\n",
       "      <td>2823.0</td>\n",
       "      <td>1048.0</td>\n",
       "      <td>3940235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>West South Central</td>\n",
       "      <td>Texas</td>\n",
       "      <td>19199.0</td>\n",
       "      <td>6111.0</td>\n",
       "      <td>28628666</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                region                 state  individuals  family_members  \\\n",
       "14  East North Central               Indiana       3776.0          1482.0   \n",
       "49  East North Central             Wisconsin       2740.0          2167.0   \n",
       "22  East North Central              Michigan       5209.0          3142.0   \n",
       "35  East North Central                  Ohio       6929.0          3320.0   \n",
       "13  East North Central              Illinois       6752.0          3891.0   \n",
       "24  East South Central           Mississippi       1024.0           328.0   \n",
       "0   East South Central               Alabama       2570.0           864.0   \n",
       "17  East South Central              Kentucky       2735.0           953.0   \n",
       "42  East South Central             Tennessee       6139.0          1744.0   \n",
       "30        Mid-Atlantic            New Jersey       6048.0          3350.0   \n",
       "38        Mid-Atlantic          Pennsylvania       8163.0          5349.0   \n",
       "32        Mid-Atlantic              New York      39827.0         52070.0   \n",
       "50            Mountain               Wyoming        434.0           205.0   \n",
       "26            Mountain               Montana        983.0           422.0   \n",
       "28            Mountain                Nevada       7058.0           486.0   \n",
       "31            Mountain            New Mexico       1949.0           602.0   \n",
       "12            Mountain                 Idaho       1297.0           715.0   \n",
       "44            Mountain                  Utah       1904.0           972.0   \n",
       "2             Mountain               Arizona       7259.0          2606.0   \n",
       "5             Mountain              Colorado       7607.0          3250.0   \n",
       "39         New England          Rhode Island        747.0           354.0   \n",
       "45         New England               Vermont        780.0           511.0   \n",
       "29         New England         New Hampshire        835.0           615.0   \n",
       "19         New England                 Maine       1450.0          1066.0   \n",
       "6          New England           Connecticut       2280.0          1696.0   \n",
       "21         New England         Massachusetts       6811.0         13257.0   \n",
       "1              Pacific                Alaska       1434.0           582.0   \n",
       "11             Pacific                Hawaii       4131.0          2399.0   \n",
       "37             Pacific                Oregon      11139.0          3337.0   \n",
       "47             Pacific            Washington      16424.0          5880.0   \n",
       "4              Pacific            California     109008.0         20964.0   \n",
       "48      South Atlantic         West Virginia       1021.0           222.0   \n",
       "7       South Atlantic              Delaware        708.0           374.0   \n",
       "40      South Atlantic        South Carolina       3082.0           851.0   \n",
       "46      South Atlantic              Virginia       3928.0          2047.0   \n",
       "20      South Atlantic              Maryland       4914.0          2230.0   \n",
       "10      South Atlantic               Georgia       6943.0          2556.0   \n",
       "33      South Atlantic        North Carolina       6451.0          2817.0   \n",
       "8       South Atlantic  District of Columbia       3770.0          3134.0   \n",
       "9       South Atlantic               Florida      21443.0          9587.0   \n",
       "34  West North Central          North Dakota        467.0            75.0   \n",
       "41  West North Central          South Dakota        836.0           323.0   \n",
       "27  West North Central              Nebraska       1745.0           676.0   \n",
       "16  West North Central                Kansas       1443.0           773.0   \n",
       "15  West North Central                  Iowa       1711.0          1038.0   \n",
       "25  West North Central              Missouri       3776.0          2107.0   \n",
       "23  West North Central             Minnesota       3993.0          3250.0   \n",
       "3   West South Central              Arkansas       2280.0           432.0   \n",
       "18  West South Central             Louisiana       2540.0           519.0   \n",
       "36  West South Central              Oklahoma       2823.0          1048.0   \n",
       "43  West South Central                 Texas      19199.0          6111.0   \n",
       "\n",
       "    state_pop  \n",
       "14    6695497  \n",
       "49    5807406  \n",
       "22    9984072  \n",
       "35   11676341  \n",
       "13   12723071  \n",
       "24    2981020  \n",
       "0     4887681  \n",
       "17    4461153  \n",
       "42    6771631  \n",
       "30    8886025  \n",
       "38   12800922  \n",
       "32   19530351  \n",
       "50     577601  \n",
       "26    1060665  \n",
       "28    3027341  \n",
       "31    2092741  \n",
       "12    1750536  \n",
       "44    3153550  \n",
       "2     7158024  \n",
       "5     5691287  \n",
       "39    1058287  \n",
       "45     624358  \n",
       "29    1353465  \n",
       "19    1339057  \n",
       "6     3571520  \n",
       "21    6882635  \n",
       "1      735139  \n",
       "11    1420593  \n",
       "37    4181886  \n",
       "47    7523869  \n",
       "4    39461588  \n",
       "48    1804291  \n",
       "7      965479  \n",
       "40    5084156  \n",
       "46    8501286  \n",
       "20    6035802  \n",
       "10   10511131  \n",
       "33   10381615  \n",
       "8      701547  \n",
       "9    21244317  \n",
       "34     758080  \n",
       "41     878698  \n",
       "27    1925614  \n",
       "16    2911359  \n",
       "15    3148618  \n",
       "25    6121623  \n",
       "23    5606249  \n",
       "3     3009733  \n",
       "18    4659690  \n",
       "36    3940235  \n",
       "43   28628666  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "homelessness_reg_fam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subsetting columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      2570.0\n",
      "1      1434.0\n",
      "2      7259.0\n",
      "3      2280.0\n",
      "4    109008.0\n",
      "Name: individuals, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Select the individuals column\n",
    "individuals = homelessness['individuals']\n",
    "\n",
    "# Print the head of the result\n",
    "print(individuals.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       2570.0\n",
       "1       1434.0\n",
       "2       7259.0\n",
       "3       2280.0\n",
       "4     109008.0\n",
       "5       7607.0\n",
       "6       2280.0\n",
       "7        708.0\n",
       "8       3770.0\n",
       "9      21443.0\n",
       "10      6943.0\n",
       "11      4131.0\n",
       "12      1297.0\n",
       "13      6752.0\n",
       "14      3776.0\n",
       "15      1711.0\n",
       "16      1443.0\n",
       "17      2735.0\n",
       "18      2540.0\n",
       "19      1450.0\n",
       "20      4914.0\n",
       "21      6811.0\n",
       "22      5209.0\n",
       "23      3993.0\n",
       "24      1024.0\n",
       "25      3776.0\n",
       "26       983.0\n",
       "27      1745.0\n",
       "28      7058.0\n",
       "29       835.0\n",
       "30      6048.0\n",
       "31      1949.0\n",
       "32     39827.0\n",
       "33      6451.0\n",
       "34       467.0\n",
       "35      6929.0\n",
       "36      2823.0\n",
       "37     11139.0\n",
       "38      8163.0\n",
       "39       747.0\n",
       "40      3082.0\n",
       "41       836.0\n",
       "42      6139.0\n",
       "43     19199.0\n",
       "44      1904.0\n",
       "45       780.0\n",
       "46      3928.0\n",
       "47     16424.0\n",
       "48      1021.0\n",
       "49      2740.0\n",
       "50       434.0\n",
       "Name: individuals, dtype: float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## different indexing\n",
    "homelessness.individuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        state  family_members\n",
      "0     Alabama           864.0\n",
      "1      Alaska           582.0\n",
      "2     Arizona          2606.0\n",
      "3    Arkansas           432.0\n",
      "4  California         20964.0\n"
     ]
    }
   ],
   "source": [
    "################################## TODO ##################################\n",
    "# Select the state and family_members columns\n",
    "state_fam = homelessness[[\"state\", \"family_members\"]]\n",
    "\n",
    "# Print the head of the result\n",
    "print(state_fam.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   individuals       state\n",
      "0       2570.0     Alabama\n",
      "1       1434.0      Alaska\n",
      "2       7259.0     Arizona\n",
      "3       2280.0    Arkansas\n",
      "4     109008.0  California\n"
     ]
    }
   ],
   "source": [
    "################################## TODO ##################################\n",
    "# Select only the individuals and state columns, in that order\n",
    "ind_state = homelessness[[\"individuals\", \"state\"]]\n",
    "\n",
    "# Print the head of the result\n",
    "print(ind_state.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subsetting rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                region       state  individuals  family_members  state_pop\n",
      "4              Pacific  California     109008.0         20964.0   39461588\n",
      "9       South Atlantic     Florida      21443.0          9587.0   21244317\n",
      "32        Mid-Atlantic    New York      39827.0         52070.0   19530351\n",
      "37             Pacific      Oregon      11139.0          3337.0    4181886\n",
      "43  West South Central       Texas      19199.0          6111.0   28628666\n",
      "47             Pacific  Washington      16424.0          5880.0    7523869\n"
     ]
    }
   ],
   "source": [
    "# Filter for rows where individuals is greater than 10000\n",
    "ind_gt_10k = homelessness[homelessness['individuals']>10000]\n",
    "\n",
    "# See the result\n",
    "print(ind_gt_10k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      region       state  individuals  family_members  state_pop\n",
      "2   Mountain     Arizona       7259.0          2606.0    7158024\n",
      "5   Mountain    Colorado       7607.0          3250.0    5691287\n",
      "12  Mountain       Idaho       1297.0           715.0    1750536\n",
      "26  Mountain     Montana        983.0           422.0    1060665\n",
      "28  Mountain      Nevada       7058.0           486.0    3027341\n",
      "31  Mountain  New Mexico       1949.0           602.0    2092741\n",
      "44  Mountain        Utah       1904.0           972.0    3153550\n",
      "50  Mountain     Wyoming        434.0           205.0     577601\n"
     ]
    }
   ],
   "source": [
    "################################## TODO ##################################\n",
    "# Filter for rows where region is Mountain\n",
    "mountain_reg = homelessness[homelessness[\"region\"]==\"Mountain\"]\n",
    "\n",
    "# See the result\n",
    "print(mountain_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    region   state  individuals  family_members  state_pop\n",
      "1  Pacific  Alaska       1434.0           582.0     735139\n"
     ]
    }
   ],
   "source": [
    "################################## TODO ##################################\n",
    "# Filter for rows where family_members is less than 1000 \n",
    "# and region is Pacific\n",
    "fam_lt_1k_pac = homelessness[(homelessness[\"family_members\"]<1000) & (homelessness[\"region\"]==\"Pacific\")]\n",
    "\n",
    "# See the result\n",
    "print(fam_lt_1k_pac)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subsetting rows by categorical variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            region                 state  individuals  family_members  \\\n",
      "7   South Atlantic              Delaware        708.0           374.0   \n",
      "8   South Atlantic  District of Columbia       3770.0          3134.0   \n",
      "9   South Atlantic               Florida      21443.0          9587.0   \n",
      "10  South Atlantic               Georgia       6943.0          2556.0   \n",
      "20  South Atlantic              Maryland       4914.0          2230.0   \n",
      "30    Mid-Atlantic            New Jersey       6048.0          3350.0   \n",
      "32    Mid-Atlantic              New York      39827.0         52070.0   \n",
      "33  South Atlantic        North Carolina       6451.0          2817.0   \n",
      "38    Mid-Atlantic          Pennsylvania       8163.0          5349.0   \n",
      "40  South Atlantic        South Carolina       3082.0           851.0   \n",
      "46  South Atlantic              Virginia       3928.0          2047.0   \n",
      "48  South Atlantic         West Virginia       1021.0           222.0   \n",
      "\n",
      "    state_pop  \n",
      "7      965479  \n",
      "8      701547  \n",
      "9    21244317  \n",
      "10   10511131  \n",
      "20    6035802  \n",
      "30    8886025  \n",
      "32   19530351  \n",
      "33   10381615  \n",
      "38   12800922  \n",
      "40    5084156  \n",
      "46    8501286  \n",
      "48    1804291  \n"
     ]
    }
   ],
   "source": [
    "# Subset for rows in South Atlantic or Mid-Atlantic regions\n",
    "south_mid_atlantic = homelessness[homelessness['region'].isin(['South Atlantic', 'Mid-Atlantic'])]\n",
    "\n",
    "# See the result\n",
    "print(south_mid_atlantic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Mojave Desert states\n",
    "canu = [\"California\", \"Arizona\", \"Nevada\", \"Utah\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      region       state  individuals  family_members  state_pop\n",
      "2   Mountain     Arizona       7259.0          2606.0    7158024\n",
      "4    Pacific  California     109008.0         20964.0   39461588\n",
      "28  Mountain      Nevada       7058.0           486.0    3027341\n",
      "44  Mountain        Utah       1904.0           972.0    3153550\n"
     ]
    }
   ],
   "source": [
    "################################## TODO ##################################\n",
    "# Filter for rows in the Mojave Desert states\n",
    "mojave_homelessness = homelessness[homelessness[\"state\"].isin(canu)]\n",
    "\n",
    "# See the result\n",
    "print(mojave_homelessness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding new columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add total col as sum of individuals and family_members\n",
    "homelessness['total'] = homelessness['individuals'] + homelessness['family_members']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "homelessness.total = homelessness.individuals + homelessness.family_members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>state</th>\n",
       "      <th>individuals</th>\n",
       "      <th>family_members</th>\n",
       "      <th>state_pop</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>East South Central</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>2570.0</td>\n",
       "      <td>864.0</td>\n",
       "      <td>4887681</td>\n",
       "      <td>3434.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pacific</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>1434.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>735139</td>\n",
       "      <td>2016.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mountain</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>7259.0</td>\n",
       "      <td>2606.0</td>\n",
       "      <td>7158024</td>\n",
       "      <td>9865.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>West South Central</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>2280.0</td>\n",
       "      <td>432.0</td>\n",
       "      <td>3009733</td>\n",
       "      <td>2712.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pacific</td>\n",
       "      <td>California</td>\n",
       "      <td>109008.0</td>\n",
       "      <td>20964.0</td>\n",
       "      <td>39461588</td>\n",
       "      <td>129972.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               region       state  individuals  family_members  state_pop  \\\n",
       "0  East South Central     Alabama       2570.0           864.0    4887681   \n",
       "1             Pacific      Alaska       1434.0           582.0     735139   \n",
       "2            Mountain     Arizona       7259.0          2606.0    7158024   \n",
       "3  West South Central    Arkansas       2280.0           432.0    3009733   \n",
       "4             Pacific  California     109008.0         20964.0   39461588   \n",
       "\n",
       "      total  \n",
       "0    3434.0  \n",
       "1    2016.0  \n",
       "2    9865.0  \n",
       "3    2712.0  \n",
       "4  129972.0  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "homelessness.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>state</th>\n",
       "      <th>individuals</th>\n",
       "      <th>family_members</th>\n",
       "      <th>state_pop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>East South Central</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>2570.0</td>\n",
       "      <td>864.0</td>\n",
       "      <td>4887681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pacific</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>1434.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>735139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mountain</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>7259.0</td>\n",
       "      <td>2606.0</td>\n",
       "      <td>7158024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>West South Central</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>2280.0</td>\n",
       "      <td>432.0</td>\n",
       "      <td>3009733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pacific</td>\n",
       "      <td>California</td>\n",
       "      <td>109008.0</td>\n",
       "      <td>20964.0</td>\n",
       "      <td>39461588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               region       state  individuals  family_members  state_pop\n",
       "0  East South Central     Alabama       2570.0           864.0    4887681\n",
       "1             Pacific      Alaska       1434.0           582.0     735139\n",
       "2            Mountain     Arizona       7259.0          2606.0    7158024\n",
       "3  West South Central    Arkansas       2280.0           432.0    3009733\n",
       "4             Pacific  California     109008.0         20964.0   39461588"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop column \"total\".\n",
    "# drop(labels, axis)\n",
    "# axis{0 or ‘index’, 1 or ‘columns’}, default 0\n",
    "# Whether to drop labels from the index (0 or ‘index’) or columns (1 or ‘columns’).\n",
    "homelessness = homelessness.drop('total', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add p_individuals col as proportion of individuals\n",
    "homelessness['p_individuals'] = homelessness['individuals']/homelessness['total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                region                 state  individuals  family_members  \\\n",
      "0   East South Central               Alabama       2570.0           864.0   \n",
      "1              Pacific                Alaska       1434.0           582.0   \n",
      "2             Mountain               Arizona       7259.0          2606.0   \n",
      "3   West South Central              Arkansas       2280.0           432.0   \n",
      "4              Pacific            California     109008.0         20964.0   \n",
      "5             Mountain              Colorado       7607.0          3250.0   \n",
      "6          New England           Connecticut       2280.0          1696.0   \n",
      "7       South Atlantic              Delaware        708.0           374.0   \n",
      "8       South Atlantic  District of Columbia       3770.0          3134.0   \n",
      "9       South Atlantic               Florida      21443.0          9587.0   \n",
      "10      South Atlantic               Georgia       6943.0          2556.0   \n",
      "11             Pacific                Hawaii       4131.0          2399.0   \n",
      "12            Mountain                 Idaho       1297.0           715.0   \n",
      "13  East North Central              Illinois       6752.0          3891.0   \n",
      "14  East North Central               Indiana       3776.0          1482.0   \n",
      "15  West North Central                  Iowa       1711.0          1038.0   \n",
      "16  West North Central                Kansas       1443.0           773.0   \n",
      "17  East South Central              Kentucky       2735.0           953.0   \n",
      "18  West South Central             Louisiana       2540.0           519.0   \n",
      "19         New England                 Maine       1450.0          1066.0   \n",
      "20      South Atlantic              Maryland       4914.0          2230.0   \n",
      "21         New England         Massachusetts       6811.0         13257.0   \n",
      "22  East North Central              Michigan       5209.0          3142.0   \n",
      "23  West North Central             Minnesota       3993.0          3250.0   \n",
      "24  East South Central           Mississippi       1024.0           328.0   \n",
      "25  West North Central              Missouri       3776.0          2107.0   \n",
      "26            Mountain               Montana        983.0           422.0   \n",
      "27  West North Central              Nebraska       1745.0           676.0   \n",
      "28            Mountain                Nevada       7058.0           486.0   \n",
      "29         New England         New Hampshire        835.0           615.0   \n",
      "30        Mid-Atlantic            New Jersey       6048.0          3350.0   \n",
      "31            Mountain            New Mexico       1949.0           602.0   \n",
      "32        Mid-Atlantic              New York      39827.0         52070.0   \n",
      "33      South Atlantic        North Carolina       6451.0          2817.0   \n",
      "34  West North Central          North Dakota        467.0            75.0   \n",
      "35  East North Central                  Ohio       6929.0          3320.0   \n",
      "36  West South Central              Oklahoma       2823.0          1048.0   \n",
      "37             Pacific                Oregon      11139.0          3337.0   \n",
      "38        Mid-Atlantic          Pennsylvania       8163.0          5349.0   \n",
      "39         New England          Rhode Island        747.0           354.0   \n",
      "40      South Atlantic        South Carolina       3082.0           851.0   \n",
      "41  West North Central          South Dakota        836.0           323.0   \n",
      "42  East South Central             Tennessee       6139.0          1744.0   \n",
      "43  West South Central                 Texas      19199.0          6111.0   \n",
      "44            Mountain                  Utah       1904.0           972.0   \n",
      "45         New England               Vermont        780.0           511.0   \n",
      "46      South Atlantic              Virginia       3928.0          2047.0   \n",
      "47             Pacific            Washington      16424.0          5880.0   \n",
      "48      South Atlantic         West Virginia       1021.0           222.0   \n",
      "49  East North Central             Wisconsin       2740.0          2167.0   \n",
      "50            Mountain               Wyoming        434.0           205.0   \n",
      "\n",
      "    state_pop     total  p_individuals  \n",
      "0     4887681    3434.0       0.748398  \n",
      "1      735139    2016.0       0.711310  \n",
      "2     7158024    9865.0       0.735834  \n",
      "3     3009733    2712.0       0.840708  \n",
      "4    39461588  129972.0       0.838704  \n",
      "5     5691287   10857.0       0.700654  \n",
      "6     3571520    3976.0       0.573441  \n",
      "7      965479    1082.0       0.654344  \n",
      "8      701547    6904.0       0.546060  \n",
      "9    21244317   31030.0       0.691041  \n",
      "10   10511131    9499.0       0.730919  \n",
      "11    1420593    6530.0       0.632619  \n",
      "12    1750536    2012.0       0.644632  \n",
      "13   12723071   10643.0       0.634408  \n",
      "14    6695497    5258.0       0.718144  \n",
      "15    3148618    2749.0       0.622408  \n",
      "16    2911359    2216.0       0.651173  \n",
      "17    4461153    3688.0       0.741594  \n",
      "18    4659690    3059.0       0.830337  \n",
      "19    1339057    2516.0       0.576312  \n",
      "20    6035802    7144.0       0.687850  \n",
      "21    6882635   20068.0       0.339396  \n",
      "22    9984072    8351.0       0.623758  \n",
      "23    5606249    7243.0       0.551291  \n",
      "24    2981020    1352.0       0.757396  \n",
      "25    6121623    5883.0       0.641849  \n",
      "26    1060665    1405.0       0.699644  \n",
      "27    1925614    2421.0       0.720777  \n",
      "28    3027341    7544.0       0.935578  \n",
      "29    1353465    1450.0       0.575862  \n",
      "30    8886025    9398.0       0.643541  \n",
      "31    2092741    2551.0       0.764014  \n",
      "32   19530351   91897.0       0.433387  \n",
      "33   10381615    9268.0       0.696051  \n",
      "34     758080     542.0       0.861624  \n",
      "35   11676341   10249.0       0.676066  \n",
      "36    3940235    3871.0       0.729269  \n",
      "37    4181886   14476.0       0.769481  \n",
      "38   12800922   13512.0       0.604130  \n",
      "39    1058287    1101.0       0.678474  \n",
      "40    5084156    3933.0       0.783626  \n",
      "41     878698    1159.0       0.721311  \n",
      "42    6771631    7883.0       0.778764  \n",
      "43   28628666   25310.0       0.758554  \n",
      "44    3153550    2876.0       0.662031  \n",
      "45     624358    1291.0       0.604183  \n",
      "46    8501286    5975.0       0.657406  \n",
      "47    7523869   22304.0       0.736370  \n",
      "48    1804291    1243.0       0.821400  \n",
      "49    5807406    4907.0       0.558386  \n",
      "50     577601     639.0       0.679186  \n"
     ]
    }
   ],
   "source": [
    "# See the result\n",
    "print(homelessness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Wrapping up\n",
    "# Create indiv_per_10k col as homeless individuals per 10k state pop\n",
    "homelessness[\"indiv_per_10k\"] = 10000 * homelessness['individuals'] / homelessness['state_pop'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################## TODO ##################################\n",
    "# Subset rows for indiv_per_10k greater than 20\n",
    "high_homelessness = homelessness[homelessness[\"indiv_per_10k\"]>20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################## TODO ##################################\n",
    "# Sort high_homelessness by descending indiv_per_10k\n",
    "high_homelessness_srt = homelessness.sort_values([\"indiv_per_10k\"], ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   state  indiv_per_10k\n",
      "8   District of Columbia      53.738381\n",
      "11                Hawaii      29.079406\n",
      "4             California      27.623825\n",
      "37                Oregon      26.636307\n",
      "28                Nevada      23.314189\n",
      "47            Washington      21.829195\n",
      "32              New York      20.392363\n",
      "1                 Alaska      19.506515\n",
      "5               Colorado      13.366045\n",
      "45               Vermont      12.492833\n",
      "19                 Maine      10.828516\n",
      "2                Arizona      10.141067\n",
      "9                Florida      10.093523\n",
      "21         Massachusetts       9.895919\n",
      "41          South Dakota       9.514077\n",
      "31            New Mexico       9.313145\n",
      "26               Montana       9.267771\n",
      "42             Tennessee       9.065763\n",
      "27              Nebraska       9.062045\n",
      "20              Maryland       8.141420\n",
      "3               Arkansas       7.575423\n",
      "50               Wyoming       7.513837\n",
      "12                 Idaho       7.409159\n",
      "7               Delaware       7.333148\n",
      "36              Oklahoma       7.164547\n",
      "23             Minnesota       7.122409\n",
      "39          Rhode Island       7.058577\n",
      "30            New Jersey       6.806193\n",
      "43                 Texas       6.706215\n",
      "10               Georgia       6.605379\n",
      "6            Connecticut       6.383837\n",
      "38          Pennsylvania       6.376884\n",
      "33        North Carolina       6.213869\n",
      "29         New Hampshire       6.169351\n",
      "25              Missouri       6.168299\n",
      "34          North Dakota       6.160300\n",
      "17              Kentucky       6.130702\n",
      "40        South Carolina       6.061970\n",
      "44                  Utah       6.037640\n",
      "35                  Ohio       5.934222\n",
      "48         West Virginia       5.658732\n",
      "14               Indiana       5.639611\n",
      "18             Louisiana       5.451006\n",
      "15                  Iowa       5.434130\n",
      "13              Illinois       5.306895\n",
      "0                Alabama       5.258117\n",
      "22              Michigan       5.217310\n",
      "16                Kansas       4.956448\n",
      "49             Wisconsin       4.718113\n",
      "46              Virginia       4.620477\n",
      "24           Mississippi       3.435066\n"
     ]
    }
   ],
   "source": [
    "################################## TODO ##################################\n",
    "# From high_homelessness_srt, select the state and indiv_per_10k cols\n",
    "result = high_homelessness_srt[[\"state\", \"indiv_per_10k\"]]\n",
    "\n",
    "# See the result\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregating Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   store type  department       date  weekly_sales  is_holiday  temperature_c  \\\n",
      "0      1    A           1 2010-02-05      24924.50       False       5.727778   \n",
      "1      1    A           2 2010-02-05      50605.27       False       5.727778   \n",
      "2      1    A           3 2010-02-05      13740.12       False       5.727778   \n",
      "3      1    A           4 2010-02-05      39954.04       False       5.727778   \n",
      "4      1    A           5 2010-02-05      32229.38       False       5.727778   \n",
      "\n",
      "   fuel_price_usd_per_l  unemployment  \n",
      "0              0.679451         8.106  \n",
      "1              0.679451         8.106  \n",
      "2              0.679451         8.106  \n",
      "3              0.679451         8.106  \n",
      "4              0.679451         8.106  \n"
     ]
    }
   ],
   "source": [
    "# Print the head of the sales DataFrame\n",
    "print(sales.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 413119 entries, 0 to 413118\n",
      "Data columns (total 9 columns):\n",
      " #   Column                Non-Null Count   Dtype         \n",
      "---  ------                --------------   -----         \n",
      " 0   store                 413119 non-null  int64         \n",
      " 1   type                  413119 non-null  object        \n",
      " 2   department            413119 non-null  int32         \n",
      " 3   date                  413119 non-null  datetime64[ns]\n",
      " 4   weekly_sales          413119 non-null  float64       \n",
      " 5   is_holiday            413119 non-null  bool          \n",
      " 6   temperature_c         413119 non-null  float64       \n",
      " 7   fuel_price_usd_per_l  413119 non-null  float64       \n",
      " 8   unemployment          413119 non-null  float64       \n",
      "dtypes: bool(1), datetime64[ns](1), float64(4), int32(1), int64(1), object(1)\n",
      "memory usage: 27.2+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Print the info about the sales DataFrame\n",
    "print(sales.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16094.726811185497\n"
     ]
    }
   ],
   "source": [
    "# Print the mean of weekly_sales\n",
    "print(sales['weekly_sales'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7682.47\n"
     ]
    }
   ],
   "source": [
    "################################## TODO ##################################\n",
    "# Print the median of weekly_sales\n",
    "print(sales[\"weekly_sales\"].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2012-10-26 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Print the maximum of the date column\n",
    "print(sales['date'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2010-02-05 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Print the minimum of the date column\n",
    "print(sales['date'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Efficient summaries : usage of .agg() method\n",
    "def iqr(column):\n",
    "    return column.quantile(0.75) - column.quantile(0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.299999999999994\n"
     ]
    }
   ],
   "source": [
    "# Print IQR of the temperature_c column\n",
    "print(sales['temperature_c'].agg(iqr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping duplicates and Counting categorical variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       store type  department       date  weekly_sales  is_holiday  \\\n",
      "0          1    A           1 2010-02-05      24924.50       False   \n",
      "10244      2    A           1 2010-02-05      35034.06       False   \n",
      "20482      3    B           1 2010-02-05       6453.58       False   \n",
      "29518      4    A           1 2010-02-05      38724.42       False   \n",
      "39790      5    B           1 2010-02-05       9323.89       False   \n",
      "\n",
      "       temperature_c  fuel_price_usd_per_l  unemployment  \n",
      "0           5.727778              0.679451         8.106  \n",
      "10244       4.550000              0.679451         8.324  \n",
      "20482       7.616667              0.679451         7.368  \n",
      "29518       6.533333              0.686319         8.623  \n",
      "39790       4.277778              0.679451         6.566  \n"
     ]
    }
   ],
   "source": [
    "# Drop duplicate store/type combinations\n",
    "store_types = sales.drop_duplicates(subset=[\"store\", \"type\"])\n",
    "print(store_types.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A    22\n",
      "B    17\n",
      "C     6\n",
      "Name: type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count the number of stores of each type\n",
    "store_counts = store_types[\"type\"].value_counts()\n",
    "print(store_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################## TODO ##################################\n",
    "# Get the proportion of stores of each type\n",
    "# store_props = ?\n",
    "print(store_props)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   store type  department       date  weekly_sales  is_holiday  temperature_c  \\\n",
      "0      1    A           1 2010-02-05      24924.50       False       5.727778   \n",
      "1      1    A           2 2010-02-05      50605.27       False       5.727778   \n",
      "2      1    A           3 2010-02-05      13740.12       False       5.727778   \n",
      "3      1    A           4 2010-02-05      39954.04       False       5.727778   \n",
      "4      1    A           5 2010-02-05      32229.38       False       5.727778   \n",
      "\n",
      "   fuel_price_usd_per_l  unemployment  \n",
      "0              0.679451         8.106  \n",
      "1              0.679451         8.106  \n",
      "2              0.679451         8.106  \n",
      "3              0.679451         8.106  \n",
      "4              0.679451         8.106  \n"
     ]
    }
   ],
   "source": [
    "# Drop duplicate store/department combinations\n",
    "store_depts = sales.drop_duplicates(subset=[\"store\", \"department\"])\n",
    "print(store_depts.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2     45\n",
      "4     45\n",
      "9     45\n",
      "7     45\n",
      "5     45\n",
      "      ..\n",
      "37    20\n",
      "50    14\n",
      "43     5\n",
      "39     5\n",
      "65     1\n",
      "Name: department, Length: 81, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count the number of each department number and sort\n",
    "dept_counts_sorted = store_depts[\"department\"].value_counts(sort=True)\n",
    "print(dept_counts_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################## TODO ##################################\n",
    "# Get the proportion of departments of each number and sort\n",
    "# dept_props_sorted = ?\n",
    "\n",
    "print(dept_props_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset the rows that are holiday weeks and drop duplicate dates\n",
    "holiday_dates = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print date col of holiday_dates\n",
    "print(holiday_dates[\"date\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What percent of sales occurred at each store type?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate total weekly sales\n",
    "sales_all = sales[\"weekly_sales\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4331014722.749999"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subset for type A stores, calculate total weekly sales\n",
    "sales_A = sales[sales[\"type\"] == \"A\"][\"weekly_sales\"].sum()\n",
    "sales_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4331014722.749999"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales[sales[\"type\"] == \"A\"].weekly_sales.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset for type B stores, calculate total weekly sales\n",
    "sales_B = sales[sales[\"type\"] == \"B\"][\"weekly_sales\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset for type C stores, calculate total weekly sales\n",
    "sales_C = sales[sales[\"type\"] == \"C\"][\"weekly_sales\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.65137469 0.28763851 0.0609868 ]\n"
     ]
    }
   ],
   "source": [
    "# Get proportion for each type\n",
    "sales_propn_by_type = [sales_A, sales_B, sales_C] / sales_all\n",
    "print(sales_propn_by_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type\n",
       "A    4.331015e+09\n",
       "B    1.912519e+09\n",
       "C    4.055035e+08\n",
       "Name: weekly_sales, dtype: float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Better solution using .groupby()\n",
    "# Group by type; calculate total weekly sales\n",
    "sales_by_type = sales.groupby(\"type\")[\"weekly_sales\"].sum()\n",
    "sales_by_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type\n",
      "A    0.651375\n",
      "B    0.287639\n",
      "C    0.060987\n",
      "Name: weekly_sales, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "################################## TODO ##################################\n",
    "# Get proportion for each type\n",
    "# sales_propn_by_type = ?\n",
    "\n",
    "print(sales_propn_by_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From previous step\n",
    "sales_by_type = sales.groupby(\"type\")[\"weekly_sales\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type  is_holiday\n",
      "A     False         4.007612e+09\n",
      "      True          3.234028e+08\n",
      "B     False         1.765411e+09\n",
      "      True          1.471081e+08\n",
      "C     False         3.772478e+08\n",
      "      True          2.825570e+07\n",
      "Name: weekly_sales, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "################################## TODO ##################################\n",
    "# Group by type and is_holiday; calculate total weekly sales\n",
    "# sales_propn_by_type_is_holiday = ?\n",
    "\n",
    "print(sales_propn_by_type_is_holiday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import NumPy with the alias np\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          min        max          mean    median\n",
      "type                                            \n",
      "A    -4988.94  474330.10  20099.568043  10105.17\n",
      "B    -3924.00  693099.36  12335.331875   6269.02\n",
      "C     -379.00  112152.35   9519.532538   1149.67\n"
     ]
    }
   ],
   "source": [
    "# For each store type, aggregate weekly_sales: get min, max, mean, and median\n",
    "sales_stats = sales.groupby(\"type\")[\"weekly_sales\"].agg([min, max, np.mean, np.median])\n",
    "\n",
    "# Print sales_stats\n",
    "print(sales_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     unemployment                          fuel_price_usd_per_l            \\\n",
      "              min     max      mean median                  min       max   \n",
      "type                                                                        \n",
      "A           3.879  14.313  7.791595  7.818             0.653034  1.180321   \n",
      "B           4.125  14.313  7.889666  7.806             0.664129  1.180321   \n",
      "C           5.217  14.313  8.934350  8.300             0.664129  1.180321   \n",
      "\n",
      "                          \n",
      "          mean    median  \n",
      "type                      \n",
      "A     0.883391  0.902676  \n",
      "B     0.892997  0.922225  \n",
      "C     0.888848  0.902676  \n"
     ]
    }
   ],
   "source": [
    "################################## TODO ##################################\n",
    "# For each store type, aggregate unemployment and fuel_price_usd_per_l: get min, max, mean, and median\n",
    "# Use groupby\n",
    "# unemp_fuel_stats = ?\n",
    "\n",
    "# Print unemp_fuel_stats\n",
    "print(unemp_fuel_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each store type, aggregate weekly_sales: get min, max, mean, and median\n",
    "sales_stats = sales.groupby(\"type\")[\"weekly_sales\"].agg([np.min, np.max, np.mean, np.median])\n",
    "sales.pivot_table(values='weekly_sales', index='type', aggfunc=[np.min, np.max, np.mean, np.median], fill_value = 0, margins=True)\n",
    "\n",
    "# Print sales_stats\n",
    "print(sales_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each store type, aggregate unemployment and fuel_price_usd_per_l: get min, max, mean, and median\n",
    "unemp_fuel_stats = sales.groupby(\"type\")[[\"unemployment\", \"fuel_price_usd_per_l\"]].agg([np.min, np.max, np.mean, np.median])\n",
    "# Print unemp_fuel_stats\n",
    "print(unemp_fuel_stats)\n",
    "\n",
    "################################## TODO ##################################\n",
    "# Create a pivot table with the same results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each pair of store type and is_holiday, aggregate unemployment and fuel_price_usd_per_l: get min, max, mean, and median\n",
    "################################## TODO ##################################\n",
    "# Use group by\n",
    "# unemp_fuel_stats_is_holyday = ?\n",
    "print(unemp_fuel_stats_is_holyday)\n",
    "################################## TODO ##################################\n",
    "# Use pivot table\n",
    "# pt_unemp_fuel_stats_is_holyday = ?\n",
    "print(pt_unemp_fuel_stats_is_holyday)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slicing and Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hyunjoon\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3165: DtypeWarning: Columns (3) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Region</th>\n",
       "      <th>Country</th>\n",
       "      <th>State</th>\n",
       "      <th>City</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Year</th>\n",
       "      <th>AvgTemperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Africa</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Algiers</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1995</td>\n",
       "      <td>64.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>Africa</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Algiers</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1995</td>\n",
       "      <td>51.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>Africa</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Algiers</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>1995</td>\n",
       "      <td>54.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>Africa</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Algiers</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>1995</td>\n",
       "      <td>56.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40</td>\n",
       "      <td>Africa</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Algiers</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1995</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Region  Country State     City  Month  Day  Year  \\\n",
       "0           0  Africa  Algeria   NaN  Algiers      1    1  1995   \n",
       "1          10  Africa  Algeria   NaN  Algiers      1   11  1995   \n",
       "2          20  Africa  Algeria   NaN  Algiers      1   21  1995   \n",
       "3          30  Africa  Algeria   NaN  Algiers      1   31  1995   \n",
       "4          40  Africa  Algeria   NaN  Algiers      2   10  1995   \n",
       "\n",
       "   AvgTemperature  \n",
       "0            64.2  \n",
       "1            51.7  \n",
       "2            54.2  \n",
       "3            56.9  \n",
       "4            59.0  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## https://www.kaggle.com/sudalairajkumar/daily-temperature-of-major-cities\n",
    "\n",
    "temperatures= pd.read_csv('temperature.csv')\n",
    "temperatures.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Unnamed: 0         Region  Country  \\\n",
      "City                                                       \n",
      "Algiers                        0         Africa  Algeria   \n",
      "Algiers                       10         Africa  Algeria   \n",
      "Algiers                       20         Africa  Algeria   \n",
      "Algiers                       30         Africa  Algeria   \n",
      "Algiers                       40         Africa  Algeria   \n",
      "...                          ...            ...      ...   \n",
      "San Juan Puerto Rico     2906280  North America       US   \n",
      "San Juan Puerto Rico     2906290  North America       US   \n",
      "San Juan Puerto Rico     2906300  North America       US   \n",
      "San Juan Puerto Rico     2906310  North America       US   \n",
      "San Juan Puerto Rico     2906320  North America       US   \n",
      "\n",
      "                                       State  Month  Day  Year  AvgTemperature  \n",
      "City                                                                            \n",
      "Algiers                                  NaN      1    1  1995            64.2  \n",
      "Algiers                                  NaN      1   11  1995            51.7  \n",
      "Algiers                                  NaN      1   21  1995            54.2  \n",
      "Algiers                                  NaN      1   31  1995            56.9  \n",
      "Algiers                                  NaN      2   10  1995            59.0  \n",
      "...                                      ...    ...  ...   ...             ...  \n",
      "San Juan Puerto Rico  Additional Territories      6   15  2013            83.2  \n",
      "San Juan Puerto Rico  Additional Territories      6   25  2013            81.0  \n",
      "San Juan Puerto Rico  Additional Territories      7    5  2013            82.9  \n",
      "San Juan Puerto Rico  Additional Territories      7   15  2013            79.7  \n",
      "San Juan Puerto Rico  Additional Territories      7   25  2013            83.7  \n",
      "\n",
      "[290633 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "# Index temperatures by city\n",
    "temperatures_ind = temperatures.set_index('City')\n",
    "\n",
    "# Look at temperatures_ind\n",
    "print(temperatures_ind)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################## TODO ##################################\n",
    "# Reset the index, keeping its contents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################## TODO ##################################\n",
    "# Reset the index, dropping its contents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Subsetting with .loc[]\n",
    "# Make a list of cities, \"Seoul\",\"Chicago\", \"Osaka\"\n",
    "cities = [\"Seoul\",\"Chicago\", \"Osaka\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset temperatures using square brackets\n",
    "print(temperatures[temperatures[\"City\"].isin(cities)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset temperatures_ind using .loc[]\n",
    "print(temperatures_ind.loc[cities])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperatures_ind.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Subsetting with .loc[]\n",
    "# Make a list of cities, Seoul, Chicago, Osaka\n",
    "cities = [\"Seoul\", \"Chicago\", \"Osaka\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################## TODO ##################################\n",
    "# Subset temperatures only for cities using square brackets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################## TODO ##################################\n",
    "# Subset temperatures_ind using .loc[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################## TODO ##################################\n",
    "# Index temperatures by country & city\n",
    "# temperatures_ind2 = ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of tuples: Brazil, Rio De Janeiro & Pakistan, Lahore\n",
    "rows_to_keep = [('US', 'Los Angeles'),('Japan','Osaka')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset for rows to keep\n",
    "print(temperatures_ind.loc[rows_to_keep])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort temperatures_ind by index values\n",
    "print(temperatures_ind.sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort temperatures_ind by index values at the city level\n",
    "print(temperatures_ind.sort_index(level=\"City\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort temperatures_ind by country then descending city\n",
    "print(temperatures_ind.sort_index(level=[\"Country\", \"City\"], ascending = [True, False]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Slicing index values\n",
    "# Sort the index of temperatures_ind\n",
    "temperatures_srt = temperatures_ind.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset rows from Pakistan to Russia\n",
    "print(temperatures_srt.loc['Pakistan':'Russia'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################## TODO ##################################\n",
    "# Try to subset rows from Lahore to Moscow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset rows from Pakistan, Lahore to Russia, Moscow\n",
    "print(temperatures_srt.loc[('Pakistan','Lahore'):('Russia','Moscow')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Slicing in both directions\n",
    "################################## TODO ##################################\n",
    "# Subset rows from India, Hyderabad to Iraq, Baghdad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset columns from date to avg_temp_c\n",
    "print(temperatures_srt.loc[:, 'Year':'AvgTemperature'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################## TODO ##################################\n",
    "# Subset in both directions at once\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Slicing time series\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a colum to temperature named date in format of yy-mm-dd\n",
    "temperatures['date'] = pd.to_datetime(temperatures[['Year','Month','Day']][:10000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Boolean conditions to subset temperatures for rows in 2010 and 2011\n",
    "temperatures_bool = temperatures[(temperatures['date'] >= '2010-01-01') & (temperatures['date'] <= '2011-12-31')]\n",
    "print(temperatures_bool)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO. Set date as an index\n",
    "temperatures_ind = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use .loc[] to subset temperatures_ind for rows from Aug 2010 to Feb 2011\n",
    "print(temperatures_ind.loc['2010-08-01':'2011-02-28'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################## TODO ##################################\n",
    "# Use .loc[] to subset temperatures_ind for rows in 2010 and 2011\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_by_country_city_vs_year = temperatures.pivot_table(values='AvgTemperature', \n",
    "                                                        index=['Country', 'City'], \n",
    "                                                        columns = 'Year',fill_value=0)\n",
    "\n",
    "# See the result\n",
    "print(temp_by_country_city_vs_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset for Egypt to India\n",
    "temp_by_country_city_vs_year.loc['Egypt':'India']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################## TODO ##################################\n",
    "# Subset for Egypt, Cairo to India, Delhi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset in both directions at once\n",
    "temp_by_country_city_vs_year.loc[('Egypt','Cairo'):('India','Delhi'),'2005':'2010']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the worldwide mean temp by year\n",
    "mean_temp_by_year = temp_by_country_city_vs_year.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for the year that had the highest mean temp\n",
    "print(mean_temp_by_year[mean_temp_by_year==mean_temp_by_year.max()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################## TODO ##################################\n",
    "# Get the mean temp by city\n",
    "# mean_temp_by_city = ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################## TODO ##################################\n",
    "# Find the city that had the lowest mean temp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Which avocado size is most popular?\n",
    "with open('avoplotto.pkl', 'rb') as f:\n",
    "    avocados = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the first few rows of data\n",
    "avocados.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import matplotlib.pyplot with alias plt\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the first few rows of data\n",
    "print(avocados.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO. Get the total number of avocados sold of each size\n",
    "nb_sold_by_size = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a bar plot of the number of avocados sold by size\n",
    "nb_sold_by_size.plot(kind='bar')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Changes in sales over time\n",
    "\n",
    "# Import matplotlib.pyplot with alias plt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "################################## TODO ##################################\n",
    "# Get the total number of avocados sold on each date\n",
    "# nb_sold_by_date = ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a line plot of the number of avocados sold by date\n",
    "nb_sold_by_date.plot(x='date')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot of nb_sold vs avg_price with title\n",
    "avocados.plot(x='nb_sold', y='avg_price', kind='scatter', title=\"Number of avocados sold vs. average price\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of conventional avg_price \n",
    "avocados[avocados[\"type\"] == \"conventional\"][\"avg_price\"].hist()\n",
    "\n",
    "# Histogram of organic avg_price\n",
    "avocados[avocados[\"type\"] == \"organic\"][\"avg_price\"].hist(alpha=0.5, bins=20)\n",
    "\n",
    "# Add a legend\n",
    "plt.legend([\"conventional\", \"organic\"])\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avocados.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Finding missing values\n",
    "\n",
    "# Import matplotlib.pyplot with alias plt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Check individual values for missing values\n",
    "avocados_2015 = avocados[avocados['year']==2015]\n",
    "print(avocados_2015.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check each column for missing values\n",
    "print(avocados_2015.isna().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar plot of missing values by variable\n",
    "avocados_2015.isna().sum().plot(kind='bar')\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Creating DataFrames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of dictionaries with new data\n",
    "avocados_list = [\n",
    "    {'date': \"2019-11-03\", 'small_sold': 10376832, 'large_sold':7835071},\n",
    "    {'date': \"2019-11-10\", 'small_sold': 10717154, 'large_sold':8561348},\n",
    "]\n",
    "\n",
    "################################## TODO ##################################\n",
    "# Convert list into DataFrame\n",
    "# avocados_2019 = ?\n",
    "##########################################################################\n",
    "\n",
    "# Print the new DataFrame\n",
    "print(avocados_2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary of lists with new data\n",
    "avocados_dict = {\n",
    "  \"date\": ['2019-11-17','2019-12-01'],\n",
    "  \"small_sold\": [10859987, 9291631],\n",
    "  \"large_sold\": [7674135, 6238096]\n",
    "}\n",
    "\n",
    "################################## TODO ##################################\n",
    "# Convert dictionary into DataFrame\n",
    "# avocados_2019 = ?\n",
    "##########################################################################\n",
    "\n",
    "# Print the new DataFrame\n",
    "print(avocados_2019)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
